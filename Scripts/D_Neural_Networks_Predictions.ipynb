{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f6a2fa1",
   "metadata": {},
   "source": [
    "#### Prediction of missing eye tracking data with neural networks\n",
    "Lucas D. Haberkamp<sup>1,2,3</sup>, Michael D. Reddix<sup>1</sup>\n",
    "\n",
    "<sup>1</sup>Naval Medical Research Unit - Dayton  \n",
    "<sup>2</sup>Oak Ridge Institute for Science and Education  \n",
    "<sup>3</sup>Leidos   \n",
    "\n",
    "---\n",
    "\n",
    "This script generates predictions for the point of gaze with the trained temporal convolutional network model (Script B) and classification predictions with the trained classifier model (Script C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9e56d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644dc014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the keras models\n",
    "tcn = tf.keras.models.load_model(\"../Models/TCN\")\n",
    "classifier = tf.keras.models.load_model(\"../Models/Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a47bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths for data which was used to scale the training dataset\n",
    "scale_x_path = '../Data/Prep/train/trainx/P01_trainx.csv'\n",
    "scale_y_path = '../Data/Prep/train/trainy-regression/P01_trainyreg.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a494fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create x and y scaler objects\n",
    "x_scaler = MinMaxScaler()\n",
    "y_scaler = MinMaxScaler()\n",
    "\n",
    "# Read the appropriate files (same ones used to fit the scaler objects during training) and fit the scaler objects\n",
    "scale_x_df = pd.read_csv(scale_x_path)\n",
    "scale_y_df = pd.read_csv(scale_y_path)\n",
    "\n",
    "x_scaler.fit(scale_x_df.values)\n",
    "y_scaler.fit(scale_y_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e23f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3D tensors for regression predictions\n",
    "def createsequences(curr_x):\n",
    "    x = tf.data.Dataset.from_tensor_slices(curr_x)\n",
    "    x = x.window(window_size, shift=1, drop_remainder=True)\n",
    "    x = x.flat_map(lambda w: w.batch(window_size))\n",
    "    x = x.batch(batch_size).prefetch(1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99539d89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# path with both training & holdout inputs\n",
    "test_x_path = '../Data/Prep/all/allx/'\n",
    "\n",
    "# columns to output in the final DataFrame\n",
    "out_cols = ['CWI_x', 'CWI_y', 'CWI_z', 'Classification', \n",
    "    'p-accelerometer', 'p-airspeed',\n",
    "    'p-attitude','p-hsi', 'p-altimeter',\n",
    "    'p-verticalspeed','p-alternates', 'p-standby',\n",
    "    'p-engine', 'p-parking','p-flap',\n",
    "    'p-misc-hdd',\n",
    "    'p-kneeboard', 'p-bugeye']\n",
    "\n",
    "window_size = 256\n",
    "batch_size = 256\n",
    "\n",
    "for i, filename in enumerate(os.listdir(test_x_path)):\n",
    "    tmp_file = os.path.splitext(filename)[0][:-5]\n",
    "    print(tmp_file)\n",
    "    f = os.path.join(test_x_path, filename)\n",
    "\n",
    "    tmp_df = pd.read_csv(f) # read the current file\n",
    "\n",
    "    x_scaled = x_scaler.transform(tmp_df.values) # scale the data with MinMaxScaler\n",
    "\n",
    "    x_test = createsequences(x_scaled) # generate sequences with the scaled data\n",
    "\n",
    "    pred = tcn.predict(x_test) # predict the point of gaze\n",
    "\n",
    "    tmp_label = classifier.predict(pred) # classify the predicted point of gaze\n",
    "\n",
    "    tmp_result = y_scaler.inverse_transform(pred) # inverse transform the predicted point of gaze data\n",
    "\n",
    "    # as predictions are autoregressive, no predictions are made for the 1st 31 values\n",
    "    result = np.zeros(shape=(tmp_df.shape[0], 3)) \n",
    "    result[window_size-1:,:] = tmp_result \n",
    "\n",
    "    label = np.zeros(shape=(tmp_df.shape[0], tmp_label.shape[1]))\n",
    "    label[window_size-1:,:] = tmp_label\n",
    "\n",
    "    # the label with the highest probability is assigned as the predicted label\n",
    "    final_label = np.argmax(label, axis=-1).astype('int')\n",
    "    final_label = np.expand_dims(final_label,axis=1)\n",
    "\n",
    "    # concatenate point of gaze, classification, and classification probablities\n",
    "    output = np.concatenate([result, final_label, label], axis=1)\n",
    "\n",
    "    # create a DataFrame and write to a .csv for further analysis\n",
    "    out_df = pd.DataFrame(output, columns=out_cols)\n",
    "    \n",
    "    out_df.to_csv('../Data/Predictions/' + tmp_file + \"_predicted.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7d080166881b4e54330c01c7c798464d68da1aa03721536117721113f4213136"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "6eaee8bb16c720efd38a5149a321ecc0a6df516b2c421a256fc4f2fc4417c56d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
